# Cluster configuration for distributed training
# Supports AWS, GCP, Azure, and on-premise deployments

clusters:
  # AWS EKS Configuration
  aws_eks:
    provider: "aws"
    region: "us-east-1"
    cluster_name: "ml-training-cluster"
    
    # Node groups
    node_groups:
      # GPU nodes for training
      gpu_training:
        instance_types:
          - "p4d.24xlarge"    # 8x A100 40GB
          - "p4de.24xlarge"   # 8x A100 80GB
        min_size: 0
        max_size: 16
        desired_size: 4
        
        # Spot configuration
        spot:
          enabled: true
          on_demand_base_capacity: 1
          on_demand_percentage_above_base: 0
          spot_allocation_strategy: "capacity-optimized-prioritized"
          
        # Node labels
        labels:
          workload: "training"
          gpu: "a100"
          
        # Taints
        taints:
          - key: "nvidia.com/gpu"
            value: "true"
            effect: "NoSchedule"
          - key: "spot"
            value: "true"
            effect: "NoSchedule"
            
      # CPU nodes for preprocessing
      cpu_preprocessing:
        instance_types:
          - "m5n.24xlarge"    # 96 vCPUs, 384 GB RAM
          - "m5dn.24xlarge"   # With NVMe SSD
        min_size: 0
        max_size: 8
        desired_size: 2
        
        spot:
          enabled: true
          on_demand_base_capacity: 0
          on_demand_percentage_above_base: 0
          
        labels:
          workload: "preprocessing"
          
    # Networking
    networking:
      vpc_cidr: "10.0.0.0/16"
      enable_nat_gateway: true
      single_nat_gateway: false  # One per AZ for HA
      enable_dns_hostnames: true
      enable_dns_support: true
      
      # Placement groups for low latency
      placement_group:
        enabled: true
        strategy: "cluster"
        
    # Storage
    storage:
      # EFS for shared storage
      efs:
        enabled: true
        performance_mode: "maxIO"
        throughput_mode: "provisioned"
        provisioned_throughput: 1024  # MB/s
        
      # FSx for Lustre for high-performance
      fsx_lustre:
        enabled: true
        storage_capacity: 1200  # GB
        deployment_type: "PERSISTENT_2"
        per_unit_storage_throughput: 1000  # MB/s/TiB
        
    # Autoscaling
    autoscaling:
      enabled: true
      metrics:
        - type: "gpu_utilization"
          target: 80
        - type: "pending_pods"
          target: 0
      scale_down_delay: "10m"
      
  # GCP GKE Configuration
  gcp_gke:
    provider: "gcp"
    region: "us-central1"
    cluster_name: "ml-training-cluster"
    
    node_pools:
      # A100 nodes
      gpu_a100:
        machine_type: "a2-highgpu-8g"  # 8x A100 40GB
        accelerator_type: "nvidia-tesla-a100"
        accelerator_count: 8
        min_count: 0
        max_count: 16
        initial_count: 4
        
        # Preemptible instances
        preemptible: true
        spot: false  # Use preemptible instead
        
        # Node config
        disk_size_gb: 1000
        disk_type: "pd-ssd"
        
      # TPU nodes (optional)
      tpu_v4:
        enabled: false
        tpu_topology: "2x2x2"
        
    # Networking
    networking:
      network: "ml-training-network"
      subnetwork: "ml-training-subnet"
      enable_private_nodes: true
      enable_private_endpoint: false
      master_ipv4_cidr: "172.16.0.0/28"
      
    # GCS for storage
    storage:
      gcs_bucket: "ml-training-checkpoints"
      gcs_class: "STANDARD"
      
  # Azure AKS Configuration
  azure_aks:
    provider: "azure"
    location: "eastus"
    resource_group: "ml-training-rg"
    cluster_name: "ml-training-cluster"
    
    node_pools:
      # GPU nodes
      gpu_compute:
        vm_size: "Standard_ND96asr_v4"  # 8x A100 40GB
        count: 4
        min_count: 0
        max_count: 16
        
        # Spot instances
        spot:
          enabled: true
          max_price: -1  # Pay up to on-demand price
          eviction_policy: "Deallocate"
          
    # Storage
    storage:
      # Azure Files
      azure_files:
        enabled: true
        sku: "Premium_LRS"
        
      # Azure Blob
      blob_container: "ml-checkpoints"
      
  # On-premise configuration
  on_premise:
    provider: "bare-metal"
    
    # Kubernetes cluster details
    kubernetes:
      api_server: "https://k8s-master.internal:6443"
      namespace: "ml-training"
      
    # Node configuration
    nodes:
      - name: "gpu-node-1"
        ip: "192.168.1.10"
        gpus: 8
        gpu_type: "A100"
        cpu_cores: 96
        memory_gb: 768
        
      - name: "gpu-node-2"
        ip: "192.168.1.11"
        gpus: 8
        gpu_type: "A100"
        cpu_cores: 96
        memory_gb: 768
        
    # Storage
    storage:
      # NFS for shared storage
      nfs:
        server: "nfs-server.internal"
        path: "/ml-training"
        
      # MinIO for S3-compatible storage
      minio:
        endpoint: "minio.internal:9000"
        access_key: "minioadmin"
        secret_key: "minioadmin"
        bucket: "ml-checkpoints"
        
    # Networking
    networking:
      mtu: 9000  # Jumbo frames
      rdma_enabled: true
      
# Multi-cloud configuration
multi_cloud:
  enabled: true
  
  # Primary cloud
  primary: "aws"
  
  # Failover configuration
  failover:
    enabled: true
    health_check_interval: 60  # seconds
    failover_threshold: 3  # consecutive failures
    
  # Cross-cloud networking
  networking:
    # VPN or dedicated connections
    interconnect:
      - type: "vpn"
        from: "aws"
        to: "gcp"
        bandwidth: "10Gbps"
        
    # Data replication
    replication:
      checkpoints: true
      datasets: false  # Too large
      
# Monitoring and observability
monitoring:
  # Prometheus
  prometheus:
    retention: "30d"
    storage_size: "100Gi"
    
  # Grafana
  grafana:
    admin_password: "admin123"  # Change in production
    
  # Alerts
  alerts:
    - name: "gpu_memory_high"
      condition: "gpu_memory_usage > 90"
      severity: "warning"
      
    - name: "node_down"
      condition: "up == 0"
      severity: "critical"
      
    - name: "training_stalled"
      condition: "rate(training_loss[5m]) == 0"
      severity: "warning"
      
# Security
security:
  # Network policies
  network_policies:
    enabled: true
    ingress_rules:
      - from: "ml-training"
        ports: [29500, 29501]  # NCCL
        
  # RBAC
  rbac:
    enabled: true
    service_account: "training-sa"
    
  # Secrets management
  secrets:
    provider: "kubernetes"  # kubernetes, vault, aws-secrets-manager
    
  # Encryption
  encryption:
    at_rest: true
    in_transit: true
    
# Disaster recovery
disaster_recovery:
  # Backup configuration
  backups:
    enabled: true
    schedule: "0 2 * * *"  # Daily at 2 AM
    retention: 30  # days
    
  # Checkpoint replication
  checkpoint_replication:
    enabled: true
    destinations:
      - "s3://backup-bucket/checkpoints"
      - "gs://backup-bucket/checkpoints"